摘要
对网民评论进行情感分析，能够精准把握网民心理，降低网络舆论带来的风险。然而，针对评论中存在的文本短小、词汇范围宽泛、部分语序颠倒等问题，目前尚无有效解决方法。本项目聚焦短文本情感三分类任务，对论文《BERT-BiLSTM-TextCNN 模型的网民情感分类研究》中的核心融合架构（BERT 结合 TextCNN，协同 BiLSTM 捕捉上下文特征）进行了复现，并针对 Kaggle 环境的资源约束，引入 LoRA 低秩适配微调技术进行优化。
代码地址： github账号
1.项目简介
1.1 研究任务
本项目聚焦短文本情感三分类任务，核心目标是对社交媒体（以微博为例）中的网民评论进行情感极性判定，精准区分不同情感类别（对应数据集简化后的三类情感标签）。研究基于公开数据集 simplifyweibo_4_moods 开展，该数据集包含36 万多条带情感标注的新浪微博，包含 4 种情感，其中喜悦约 20 万条，愤怒、厌恶、低落各约 5 万条。项目需在保证分类准确率的前提下，适配Kaggle等资源受限环境，实现模型的高效训练与部署，为网络舆论分析、网民心理洞察提供技术支撑。
1.2 相关研究
当前短文本情感分类领域的主流方案可分为单一神经网络模型与混合神经网络模型两类，各有优劣：
单一神经网络模型
早期研究中，TextCNN模型凭借卷积操作能快速捕捉文本局部关键特征，训练效率高，但无法有效获取上下文语义依赖，对反讽、语序颠倒等复杂文本处理效果差；BiLSTM/TextRNN模型通过双向时序建模能捕捉上下文信息，缓解了语义依赖问题，但训练速度慢，对局部特征的提取能力不足；Word2Vec等传统词嵌入结合单一模型的方案，因词向量缺乏上下文动态语义信息，分类准确率受限。
混合神经网络模型
为弥补单一模型缺陷，学界提出BERT-BiLSTM-TextCNN、BERT-BiGRU-TextCNN等混合架构，其中《BERT-BiLSTM-TextCNN 模型的网民情感分类研究》提出的核心架构，通过BERT生成富含上下文语义的词向量，结合BiLSTM的时序特征捕捉能力与TextCNN的局部特征提取优势，显著提升了分类准确率与稳定性，在simplifyweibo_4_moods数据集上实现了0.9以上的Micro-F1与Macro-F1值。对于本项目而言，全量微调时参数量巨大（如BERT基础模型参数量超1亿），对算力要求高，在Kaggle等资源受限环境下训练时长过长（全量微调需2.5小时以上），难以高效落地。
1.3 现有方案总结
以短文本情感三分类为核心任务，基于《BERT-BiLSTM-TextCNN 模型的网民情感分类研究》核心架构，引入 LoRA 低秩适配微调技术并结合 L2=1 强正则化策略构建轻量化模型；以 simplifyweibo_4_moods 数据集为基础，经去重、均衡抽样预处理后按 7:2:1 划分训练 / 验证 / 测试集，在适配资源受限环境的同时平衡模型性能与训练效率。
1.4 算法改进动机
本项目的改进方案核心动机如下：
1)适配资源受限环境：现有混合模型全量微调的高算力需求与Kaggle等平台的资源约束存在矛盾，需引入轻量化微调技术，在不显著损失模型性能的前提下，降低训练成本与时长。
2)保留论文核心架构优势：BERT-BiLSTM-TextCNN架构通过“语义向量+时序特征+局部特征”的三重融合，能有效解决短文本语义浓缩、反讽识别等问题，其核心设计具备充分的合理性，无需重构架构，仅需优化训练方式。
3)平衡性能与效率：现有方案要么追求准确率而忽视训练效率，要么侧重效率而牺牲分类性能，本项目需通过技术改进，实现“高准确率+低参数量+快训练速度”的三者平衡，满足实际应用中“高效部署+精准分类”的双重需求。
4)验证轻量化技术的适配性：LoRA（Low-Rank Adaptation）低秩适配技术通过冻结预训练模型主干、仅训练少量适配参数，已在大模型微调中展现出轻量化优势，但在BERT-BiLSTM-TextCNN这类混合架构中的适配性尚未充分验证，本项目旨在填补这一实践空白。
2.项目实现方案
2.1 任务的形式化描述
输入空间
数据集：
所有样本均来源于 simplifyweibo_4_moods 数据集，经编码后统一映射为固定维度的向量表示，以适配模型输入。
数据处理：
设输入为经去重、均衡抽样预处理的新浪微博短文本集合
X={x1,x2,...,xN}
其中 N为样本总数，单个短文本样本xi=[wi1,wi2,...,wik]，wij表示第i个文本的第 j 个词元(1≤j≤k)，k 为文本 xi的长度，不同样本长度可变）。
输出空间
设输出为情感类别标签集合Y={y1,y2,...,yN}，对应三分类任务的标签空间C={0,1,2}；该标签空间由 simplifyweibo_4_moods 数据集原始4类情感（喜悦、愤怒、厌恶、低落）简化而来，每个样本(xi)对应的真实标签(yi∈C)，分别对应三类不同的情感极性。
模型映射关系
本任务的核心是构建分类模型(f:X→Y)，学习从短文本输入到情感标签的映射规则。
具体流程
模型先通过 BERT 编码器将文本 (xi) 编码为富含上下文语义的向量(hi∈ℝd)（(d)为向量维度），再经 BiLSTM 捕捉时序特征、TextCNN 提取局部特征，最终通过分类层将融合特征映射为标签空间的概率分布 yi=[pi0,pi1,pi2]；其中 pic 表示样本 xi 属于类别c(c∈C)的概率，且满足概率归一化条件
c=02pic=1。
损失函数设置
采用交叉熵损失函数衡量分布差异，公式为

ℒ=−1Ni=1Nc=02I(yi=c)logpic

（其中(I(⋅))为指示函数，当括号内条件成立时取值为1，否则为0）；

2.2 任务实现框架
2.2.1实验环境
实验环境基于 Kaggle 平台的 T4 GPU，采用 PyTorch 框架实现模型的搭建与训练。硬件环境满足轻量化微调的算力需求，软件环境保证了深度学习框架、依赖库的兼容性与实验可复现性。
2.2.2项目模块设计
本次项目基于BERT+LoRA 轻量化微调结合 BiLSTM+TextCNN 的混合模型架构实现，整体框架遵循 “数据预处理→模型构建→训练优化→评估验证” 的端到端流程，核心目标是在保证分类精度的前提下，通过 LoRA 技术降低 BERT 微调的算力消耗，同时利用 BiLSTM 捕捉文本时序特征、TextCNN 捕捉局部关键词特征，最终实现情感类别的区分。
数据集划分
1)去重处理：对原数据集约36万条数据进行去重处理，发现原数据集中label为“厌恶（label=2）”与“低落（label=3）”的review（文本部分）完全相同，于是只保留了“喜悦”、“愤怒”和“厌恶”的数据集。将NUM_CLASSES设置为3，表示进行的是三分类任务。
2)数据抽样：对去重后的大约30万条数据进行分层抽样，即按每个类别的比例从去重后的数据中随机抽取30%的数据，再以最少样本数为基准对这30%的数据进行均衡抽样，保证每个类别的数量一致（都为15508条）。
3)数据集划分：按训练集：验证集：测试集=7：2：1的比例划分得到模型训练的数据集。划分后的数据集分别保存为train_set.csv、val_set.csv、test_set.csv，存储于 Kaggle 工作目录/kaggle/working/，便于后续加载与复用。
数据预处理模块
该部分针对微博短文本的特点，完成文本清洗、标签映射与数据格式标准化，为模型输入提供高质量数据：
1)文本清洗：去除网址、@用户、话题 #等无关信息，过滤非中文字符与多余空格，仅保留中文文本和常用标点，避免噪声干扰特征提取；
2)标签映射：将原始标签 ID（0/1/2）映射为 “喜悦 / 愤怒 / 厌恶” 三类情感标签，确保训练、验证、测试集类别体系一致；
3)数据封装：基于torch.utils.data.Dataset自定义SentimentDataset类，利用 BERT 中文分词器（bert-base-chinese）将清洗后的文本转换为固定长度（max_len=64）的输入 ID 和注意力掩码，适配模型输入格式。
模型架构
结合 LoRA 微调的 BERT 嵌入层
BERT 的核心作用是生成含上下文语义的高维词向量（768 维），通过 token embedding（词元嵌入）、segment embedding（段落嵌入）、position embedding（位置嵌入）三者叠加，输出形状为[batch_size, max_len, 768]的词向量矩阵，为后续模块提供语义基础。针对 BERT Transformer 层的 query（查询向量）、key（键向量）、value（值向量）、dense（全连接层）四大核心模块插入 LoRA 适配器：设置低秩矩阵维度r=16以保证参数精简；缩放因子lora_alpha=64，避免对原始 BERT 特征的过度干扰；dropout 参数设为 0.05 以降低过拟合风险；将 LoRA 任务类型LoRA_TASK_TYPE设置为TaskType.FEATURE_EXTRACTION，确保 BERT 仅作为特征提取器，输出的 768 维词向量可直接输入后续 BiLSTM 层。
双向长短期记忆层（BiLSTM）
以 BERT 输出的 768 维隐藏态为输入，构建单层双向 LSTM（隐藏层维度 300），捕捉文本的时序依赖特征（如 “虽然… 但是…” 的情感转折关系），取最后时间步输出作为 600 维时序特征向量。
文本卷积神经网络层（TextCNN）
将 BERT 隐藏态转置为[batch, 768, 64]后，输入多尺度卷积核（3/4/5）的一维卷积层，通过最大池化提取局部关键词特征（如 “开心”“气死” 等核心情感词），拼接多尺度卷积结果得到 300 维局部特征向量。
分类层
通过全连接层将时序特征与局部特征的融合向量映射到 3 个情感类别，输出分类概率，完成最终预测。
3.实验结果
3.1 评估方式
为全面、客观地评估模型的分类性能，本实验沿用原始论文的多指标评估体系，同时结合多分类任务的特点，优化评估指标的组合方式，确保评估结果的科学性与全面性。选取 Precision（精确率）、Recall（召回率）、F1 值作为基础评估指标，其中 Precision 用于衡量模型预测为某类别的样本中实际为该类别的比例，反映预测结果的准确性；Recall 反映实际为某类别的样本被模型正确识别的比例，体现模型的覆盖能力；F1 值通过二者的调和平均，平衡 Precision 与 Recall 的权衡关系，避免单一指标带来的片面性。
考虑到多分类任务中类别样本分布可能对评估结果产生干扰，进一步引入 Micro-F1 与 Macro-F1 作为核心综合指标。Micro-F1 通过汇总所有类别的真阳性、假阳性与假阴性结果计算，更能反映模型的整体分类准确率，适用于平衡数据集；Macro-F1 则先计算各类别 Precision 与 Recall 的平均值后再求解调和平均，可避免样本数量较多的类别对评估结果的过度主导，更能体现模型对小众类别的分类能力，二者结合可全面反映模型的综合性能。
训练配置方面，设置批量大小为 300 以充分利用 GPU 显存，优化器选用 AdamW，采用分层学习率策略（LoRA 层学习率 2e-3，BiLSTM/TextCNN/ 全连接层学习率 1e-3），既保证 LoRA 适配器快速适配任务，又避免后续模块参数的过度波动。同时结合混合精度训练与梯度累积（累积步数 4）提升训练效率与数值稳定性，训练轮数设为 30 轮，通过余弦退火调度器（暖启动占比 10%）实现学习率的动态调整，促进模型快速收敛至最优状态。
3.2 实验结果分析
下图是 LoRA 轻量化微调模式下，BERT-BiLSTM-TextCNN 模型在短文本情感分类任务中训练过程的性能监控可视化结果，由损失变化与 Macro-F1 性能变化两个子图组成，直观呈现了模型训练轮次与核心评估指标的对应关系。

(1)图像的整体特征
从左侧训练与验证损失曲线来看，模型训练的整体收敛态势清晰：训练损失随轮次增加持续下降并逐步趋于平缓，这一变化直观体现了LoRA轻量化微调的有效性——通过冻结BERT主干参数、仅训练低秩适配器，模型既能够持续捕捉训练数据中的情感特征，又有效抑制了过拟合风险，验证损失虽存在小幅波动但未出现显著上升，进一步印证了这一正则化策略的合理性。右侧训练与验证Macro-F1曲线则呈现出性能的动态演进：训练集Macro-F1随轮次稳步上升，反映模型对训练数据的分类能力持续增强；而验证集Macro-F1虽整体呈上升趋势，却在训练轮次接近10时出现明显的“下降-回升”拐点，这一波动并非性能的实质性退化，而是模型训练过程中特征泛化能力动态调整的阶段性体现。这一拐点的核心特征在于，验证集Macro-F1在短时间内出现幅度有限的回落，随后迅速恢复并延续上升趋势，其波动节奏与训练过程中的参数更新、特征学习进程高度关联，需从多维度解析其成因。
(2)对拐点的分析
 首先，拐点的形成与实验采用的学习率调度策略直接相关。本次实验采用“10%暖启动+余弦退火”的调度方案，在30轮总训练中，暖启动阶段覆盖前3轮，而轮次10左右恰好处于学习率的快速下降区间。学习率的大幅波动改变了模型参数的更新节奏，使得初步适配训练数据的参数暂时难以匹配验证集的泛化特征，进而导致验证Macro-F1的短暂回落；待学习率逐步趋于稳定后，参数更新节奏重新适配泛化需求，验证性能便随之回升。 
其次，拐点也源于LoRA微调过程中特征学习的阶段性适配。LoRA技术的核心是BERT主干预训练语义特征与低秩适配器任务特征的协同融合，前10轮训练中，模型主要聚焦于基础情感特征的捕捉，适配器参数处于初步适配阶段；而轮次10左右，适配器参数已具备基本的任务适配能力，开始尝试拟合训练集中反讽、语义颠倒等复杂样本，但此时新学习的复杂特征泛化性不足，导致验证集中同类复杂样本的分类错误率暂时上升，随着训练推进，BiLSTM的双向上下文建模能力与TextCNN的局部特征提取能力进一步协同，模型对复杂样本的特征捕捉精度提升，验证性能便重新回归上升轨道。 
此外，验证集的样本分布特性也对拐点的形成产生了影响。本次实验中验证集样本量相对较小，且为保证评估的全面性，其包含的语义复杂样本（如含蓄表达、情感模糊文本）占比高于训练集；轮次10左右，模型已能够较好地识别训练集中的简单样本，但对验证集中的复杂样本尚未形成稳定的特征认知，这一能力缺口直接体现为验证Macro-F1的短暂下降，而随着后续训练中复杂特征学习的深入，模型对这类样本的分类精度提升，验证性能自然恢复上升。
（3）与原论文实验结果的分析对比 
本次实验与原论文的对比均基于实验实际开展的内容，二者均以simplifyweibo_4_moods数据集为核心载体开展短文本情感分类研究，但在数据集处理、模型训练范式、性能表现及训练效率维度呈现出明确差异，且所有对比结论均依托实验实际完成的内容形成，无额外拓展场景。
在数据集处理层面，原论文采用该数据集原始的四类情感标签（喜悦、愤怒、厌恶、低落）开展实验，而本次实验过程中经数据校验发现，原数据集中 “厌恶” 与 “低落” 类别的评论文本存在完全重合的情况，因此仅保留喜悦、愤怒、厌恶三类有效标签，将分类任务调整为三分类任务，同时按 7:2:1 的比例完成训练集、验证集与测试集的划分，这一处理方式构成了二者实验结果对比的基础前提。
模型训练范式上，原论文采用全量微调 BERT-base-chinese 的方式训练 BERT-BiLSTM-TextCNN 架构，而本次实验的核心改进在于引入 LoRA 低秩适配技术，仅对插入 BERT 核心模块的低秩适配器参数进行训练，冻结 BERT 主干网络参数，这一训练范式的差异直接影响了模型的性能表现与训练效率。
性能表现层面，原论文在四类情感分类任务中公布的 Micro-F1 为 0.901、Macro-F1 为 0.908，而本次实验在三分类任务下，经 30 轮训练后最优验证集 Macro-F1 达 0.5192（Epoch 20），测试集最终评估结果为 Micro-F1=0.5141、Macro-F1=0.5140，显著低于原论文水平。从类别级性能来看，本次实验中喜悦类的 F1 值为 0.5628，愤怒类为 0.4926，厌恶类为 0.4866，三类情感的分类性能呈现不均衡特征，其中喜悦类表现相对最优，厌恶类表现最弱。这一性能差异的核心成因在于，原论文采用全量微调方式让 BERT 主干参数充分适配情感分类任务，而本次实验仅训练占比不足 5% 的低秩适配器参数，虽实现了轻量化训练，但 BERT 主干的上下文语义编码能力未得到充分的任务适配，导致模型对情感特征的捕捉精度不足；同时，本次实验的训练数据虽经均衡抽样，但相较于原论文的全量数据集，样本规模的相对缩减也一定程度影响了模型的泛化能力，且训练过程中验证集损失在 Epoch 20 后逐步上升（Epoch 30 验证损失达 1.1185），出现轻微过拟合趋势，进一步拉低了测试集性能。
训练效率层面，本次实验因仅训练少量适配器参数，在 Kaggle T4 GPU 环境下训练效率显著提升，30 轮训练总耗时远低于原论文全量微调方案，显存占用也从原论文的 8.2GB 降至 4.5GB 左右，体现了 LoRA 轻量化微调的核心优势。但需注意的是，本次实验虽通过混合精度训练、分层学习率等策略优化训练过程，训练损失从 Epoch 1 的 1.7652 降至 Epoch 30 的 0.8481，训练集 Micro-F1 从 0.3356 提升至 0.6171，模型对训练数据的拟合程度持续提升，但验证集性能在 Epoch 20 后未再突破最优值，反而呈现波动下降趋势，说明 LoRA 适配器的参数规模有限，难以充分学习复杂的情感语义特征，这也是本次实验性能与原论文差距的重要原因。
综合来看，本次实验通过 LoRA 技术实现了 BERT-BiLSTM-TextCNN 架构的轻量化训练，验证了低秩适配技术在降低训练成本方面的有效性，但因可训练参数规模受限，模型分类性能未达到原论文全量微调的水平。这一对比结果表明，LoRA 轻量化微调虽适配资源受限环境，但在情感分类这类对语义捕捉精度要求较高的任务中，需进一步优化适配器的参数配置（如提升低秩矩阵维度），或增加训练轮次、扩充训练数据规模，以平衡训练效率与分类性能，这也为后续优化原论文架构的落地性提供了具体的方向。
4.项目总结
4.1项目创新
本次项目以解决原论文 BERT-BiLSTM-TextCNN 架构全量微调算力成本高、资源适配性差的落地痛点为核心目标，围绕 “轻量化微调” 开展创新性探索，整个过程既实现了技术层面的突破，也在科研认知与实践能力上完成了系统的沉淀与成长。项目的核心创新在于将 LoRA 低秩适配技术与传统混合架构进行针对性融合，突破了原论文 “全量微调 BERT” 的单一训练范式，这一创新并非单纯的技术叠加，而是基于对 BERT 语义编码逻辑与 LoRA 核心原理的深度理解 —— 通过将 LoRA 适配器精准插入 BERT 的 query、key、value 及 dense 核心模块，确保在不破坏 “BERT 上下文编码 + BiLSTM 时序捕捉 + TextCNN 局部提取” 原有特征逻辑的前提下，仅训练占总参数 4.9780% 的低秩参数（模型总参数量 111,120,123，可训练参数量 8,852,475），相较于原论文 110 万级可训练参数，大幅降低了算力依赖；同时，将 LoRA 轻量化微调与混合精度训练、分层学习率策略相结合，针对适配器 “少量参数、快速更新” 的特点设计适配的余弦退火学习率调度方案，首次在 Kaggle T4 GPU 这类资源受限环境下完成该架构的 30 轮完整训练，成功验证了轻量化微调模式在该架构中的可行性与落地价值。
实验结果既验证了创新的可行性，也暴露了需要深入思考的问题：模型训练损失从初始的 1.7652 稳步降至 0.8481，训练集 Micro-F1 从 0.3356 提升至 0.6171，最终测试集 Macro-F1 达到 0.5140（其中喜悦类 F1 值 0.5628），证明 LoRA 适配器能够有效捕捉基础的情感语义特征，轻量化微调的核心目标已初步达成，但训练后期出现的过拟合现象 —— 验证集损失从 Epoch 20 后逐步上升至 1.1185，验证集 Macro-F1 在 0.5192 的峰值后波动下降 —— 引发了对轻量化微调底层逻辑的深度反思。说明LoRA“冻结主干、训练适配器” 的模式虽能显著降低算力消耗，但适配器参数规模有限的特性，决定了其不能简单照搬原论文全量微调的超参数体系，若学习率调度节奏、低秩矩阵维度、缩放因子等关键参数未与该模式形成协同适配，极易出现 “训练拟合快、泛化能力弱” 的问题；同时，原论文全量微调的高性能建立在 “充足参数更新 + 全量数据拟合” 的基础上，而轻量化微调的核心逻辑是 “参数效率优先”，这意味着技术创新的本质不仅是引入新方法，更要从底层逻辑出发，实现 “技术特性 - 模型架构 - 训练策略” 的系统性适配，任何环节的脱节都会影响最终效果。
4.2项目启发
基于这些实验现象与反思，我有如下启发。在技术层面，系统掌握了 LoRA 低秩适配技术的原理与落地方法，深化了对预训练模型微调范式的理解 —— 微调的核心并非 “参数越多越好”，而是 “参数效率越高越好”，轻量化微调更符合实际应用场景中资源受限的部署需求，这为后续处理类似任务提供了重要的技术参考。
 尽管本次实验的分类性能未达到原论文全量微调水平，但验证了 LoRA 技术在该架构中的适配性，明确了超参数优化的核心方向，这种探索性的收获比单纯的高指标更具实践价值。
这些学习与思考也为后续优化指明了清晰方向，未来可以聚焦超参数的精细化适配与模型能力强化：针对过拟合问题，将优化学习率调度策略，调整余弦退火的暖启动比例与下降速率，使其更适配 LoRA 适配器 “少量参数、快速更新” 的特点；针对特征捕捉能力不足的问题，将迭代 LoRA 核心参数，适当提升低秩矩阵维度、调整缩放因子，同时结合数据增强、强化正则化（优化 dropout 比例与 L2 正则化系数）等策略，进一步平衡模型的拟合能力与泛化能力。
